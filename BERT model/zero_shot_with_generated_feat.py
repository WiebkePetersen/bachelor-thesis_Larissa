from transformers import pipeline
import json
from deep_translator import GoogleTranslator
import re
import pandas as pd
from serious_generating import *


features = pd.read_csv("C:\\Users\\laris\\Desktop\\GitHub\\bachelor-thesis\\Daten\\Features_clean.csv", sep=';', usecols=[2,3,7], encoding="latin-1")   # HIER CONFIG EINFÜGEN


def clean_features(translate:bool):
    """
    This function extracts the features of the Pseudowörter and cleans them.
    After that it splits them into neutral and emotional features and returns a 
    json-file with a list of lists of these cleaned and split features.

    Parameters:
    -----------
    translate : boolean
        If translate is True, the features are translated into English.
        If it is False, they stay in German.
    
    Returns:
    --------
        Returns a json-file with a list of lists of the cleaned and split features.
    """

    associations_neu = []
    associations_emo = []
    filename = "asso_split.txt" # HIER CONFIG EINFÜGEN


    for i in range(len(features)):

        if str(features['features'][i]) != "nan" and str(features['features'][i]) != "Fail" and str(features['features'][i]) != ",":

            clean_association = re.sub(r',', '', features['features'][i])
            clean_association = re.sub(r'\s*\+\s*', ', ', clean_association)

            if translate == True:
                clean_association = GoogleTranslator(source='auto', target='en').translate(clean_association)
                filename = "translated_asso_split.txt"   # HIER CONFIG EINFÜGEN

            if features["emotionality"][i] == "neu":
                associations_neu.append(clean_association)

            if features["emotionality"][i] == "neu":
                associations_emo.append(clean_association)


    all_associations = [associations_emo, associations_neu]

    with open(filename, "w") as f2out:
        json.dump(all_associations, f2out)





def zero_shot_generatedText_en():
    """
    This function takes the associations created by the study participants and 
    the associations generated by the pipeline in English and passes them together 
    through a zero-shot pipeline. Following this, two json files (emotional and neutral) 
    are created containing the result of the pipeline. The result answers the 
    question, which study participant associations were assigned to which 
    generated associations?

    Parameters:
    -----------
    -
    
    Returns:
    --------
        Returns two json-files with the assignments of the generated associations to the ones from study participants.
    """
    
    try:
        data = open("translated_asso_split.txt")   # HIER CONFIG EINFÜGEN
        data = json.load(data)

        participant_associations_emo = data[0]
        participant_associations_neu = data[1]

    except FileNotFoundError:
        clean_features(features, translate=True)
    

    try:
        generated_neu = []
        generated_emo = []


        generated_file = open("generated.txt")   # HIER CONFIG EINFÜGEN
        generated_file = json.load(generated_file)

    except FileNotFoundError:
        generating_english_features()


    regex = r'^(.*?)I associate it with'

    for dict in generated_file:

        if "emotional" in list(dict.keys())[0]:

            generated_text = dict.get(list(dict.keys())[0])
            generated_association = re.sub(regex, '', generated_text)
            generated_emo.append(generated_association.split(".")[0])

        if "neutral" in list(dict.keys())[0]:

            generated_text = dict.get(list(dict.keys())[0])
            generated_association = re.sub(regex, '', generated_text)
            generated_neu.append(generated_association.split(".")[0])

    #uni_chr_re = re.compile(r'\\u([a-fA-F0-9]{4})')

    #generated_neu_clean = []
    #generated_emo_clean = []

    """ for ele in generated_emo:

        generated_emo_clean.append(uni_chr_re.sub(lambda m: chr(int(m.group(1), 16)), ele))


    for ele2 in generated_neu:

        generated_neu_clean.append(uni_chr_re.sub(lambda m: chr(int(m.group(1), 16)), ele2))
        """

    #for i in range(len(generated_emo)):
    #    generated_emo_clean.append(uni_chr_re.sub(lambda m: chr(int(m.group(1), 16)), generated_emo[i]))
    #    generated_neu_clean.append(uni_chr_re.sub(lambda m: chr(int(m.group(1), 16)), generated_neu[i]))



    classifier_neu = pipeline("zero-shot-classification", model="facebook/bart-base", multi_label=True)  # model="bert-base-german-cased"
    #result = classifier_neu(generated_neu_clean, candidate_labels=assoziationen_neu)

    with open("zero_shot_english_generatedtext_neu.txt", "w") as fout:   # HIER CONFIG EINFÜGEN
        json.dump(classifier_neu(generated_neu, candidate_labels=participant_associations_neu), fout)



    classifier_emo = pipeline("zero-shot-classification", model="facebook/bart-base", multi_label=True)  # model="bert-base-german-cased"
    #result = classifier_emo(generated_emo_clean, candidate_labels=assoziationen_emo)

    with open("zero_shot_english_generatedtext_emo.txt", "w") as fout:    # HIER CONFIG EINFÜGEN
        json.dump(classifier_emo(generated_emo, candidate_labels=participant_associations_emo), fout)





def zero_shot_generatedText_de():
    """
    This function takes the associations created by the study participants and 
    the associations generated by the pipeline in German and passes them together 
    through a zero-shot pipeline. Following this, two json files (emotional and neutral) 
    are created containing the result of the pipeline. The result answers the 
    question, which study participant associations were assigned to which 
    generated associations?

    Parameters:
    -----------
    -
    
    Returns:
    --------
        Returns two json-files with the assignments of the generated associations to the ones from study participants.
    """

    try:
        data = open("asso_split_de.txt")   # HIER CONFIG EINFÜGEN
        data = json.load(data)

        participant_associations_emo = data[0]
        participant_associations_neu = data[1]

    except FileNotFoundError:
        clean_features(features, translate=False)

    try: 
        generated_neu = []
        generated_emo = []

        generated_file = open("generated_de.txt")    # HIER CONFIG EINFÜGEN
        generated_file = json.load(generated_file)

    except FileNotFoundError:
        generating_german_features()


    regex = r'^(.*?)und wenn ich daran denke, assoziiere ich es mit'

    for dict in generated_file:

        if "emotional" in list(dict.keys())[0]:

            generated_text = dict.get(list(dict.keys())[0])
            generated_text = generated_text.get("generated_text")
            generated_association = re.sub(regex, '', generated_text)
            generated_emo.append(generated_association.split(".")[0].strip())

        if "neutral" in list(dict.keys())[0]:

            generated_text = dict.get(list(dict.keys())[0])
            generated_text = generated_text.get("generated_text")
            generated_association = re.sub(regex, '', generated_text)
            generated_neu.append(generated_association.split(".")[0].strip())

    uni_chr_re = re.compile(r'\\u([a-fA-F0-9]{4})')

    generated_neu_clean = []
    generated_emo_clean = []

    """for ele in generated_emo:
        generated_emo_clean.append(uni_chr_re.sub(lambda m: chr(int(m.group(1), 16)), ele))

    for ele2 in generated_neu:
        generated_neu_clean.append(uni_chr_re.sub(lambda m: chr(int(m.group(1), 16)), ele2)) """

    for i in range(len(generated_emo)):
        generated_emo_clean.append(uni_chr_re.sub(lambda m: chr(int(m.group(1), 16)), generated_emo[i]))
        generated_neu_clean.append(uni_chr_re.sub(lambda m: chr(int(m.group(1), 16)), generated_neu[i]))



    classifier_neu = pipeline("zero-shot-classification", model="distilbert-base-german-cased", multi_label=True)  # model="bert-base-german-cased"
    #result = classifier_neu(generated_neu_clean, candidate_labels=assoziationen_neu)

    with open("zero_shot_generatedtext_neu_de.txt", "w") as fout:       # HIER CONFIG EINFÜGEN
        json.dump(classifier_neu(generated_neu_clean, candidate_labels=participant_associations_neu), fout)



    classifier_emo = pipeline("zero-shot-classification", model="distilbert-base-german-cased", multi_label=True)  # model="bert-base-german-cased"
    #result = classifier_emo(generated_emo_clean, candidate_labels=assoziationen_emo)

    with open("zero_shot_generatedtext_emo_de.txt", "w") as fout:         # HIER CONFIG EINFÜGEN
        json.dump(classifier_emo(generated_emo_clean, candidate_labels=participant_associations_emo), fout)
