from transformers import pipeline
import json
import re
import pandas as pd
#from serious_generating import *


features = pd.read_csv("C:\\Users\\laris\\Desktop\\GitHub\\bachelor-thesis\\BERT model\\TranslatednewData.csv", sep='\t', usecols=[1, 2, 3, 6], encoding="utf-8")   # HIER CONFIG EINFÜGEN


def clean_features(features):
    """
    This function extracts the features of the Pseudowörter and cleans them.
    After that it splits them into neutral and emotional features and returns a 
    json-file with a list of lists of these cleaned and split features.

    Parameters:
    -----------
    translate : boolean
        If translate is True, the features are translated into English.
        If it is False, they stay in German.
    
    Returns:
    --------
        Returns a json-file with a list of lists of the cleaned and split features.
    """

    associations_neu = []
    associations_emo = []
    filename = "C:\\Users\\laris\\Desktop\\GitHub\\bachelor-thesis\\BERT model\\translated_asso_split.json" # HIER CONFIG EINFÜGEN


    for i in range(len(features)):

        if str(features['features'][i]) != "nan" and str(features['features'][i]) != "Fail" and str(features['features'][i]) != ",":

            clean_association = re.sub(r'\s*\+\s*', ', ', features['features'][i])

            if features["emotionality"][i] == "neu":
                associations_neu.append(clean_association)

            if features["emotionality"][i] == "emo":
                associations_emo.append(clean_association)


    all_associations = [associations_emo, associations_neu]

    with open(filename, "w") as f2out:
        json.dump(all_associations, f2out)





def zero_shot_generatedText_en():
    """
    This function takes the associations created by the study participants and 
    the associations generated by the pipeline in English and passes them together 
    through a zero-shot pipeline. Following this, two json files (emotional and neutral) 
    are created containing the result of the pipeline. The result answers the 
    question, which study participant associations were assigned to which 
    generated associations?

    Parameters:
    -----------
    -
    
    Returns:
    --------
        Returns two json-files with the assignments of the generated associations to the ones from study participants.
    """
    
    #try:
    data = open("C:\\Users\\laris\\Desktop\\GitHub\\bachelor-thesis\\BERT model\\translated_asso_split.json")   # HIER CONFIG EINFÜGEN
    data = json.load(data)

    participant_associations_emo = data[0]
    participant_associations_neu = data[1]

    #except FileNotFoundError:
    #    clean_features(features)
    

    #try:
    generated_file = open("C:\\Users\\laris\\Desktop\\GitHub\\bachelor-thesis\\BERT model\\generated_en.json")   # HIER CONFIG EINFÜGEN
    generated_file = json.load(generated_file)

    generated_neu = []
    generated_emo = []

    #except FileNotFoundError:
    #    generating_english_features()


    regex = r'^(.*?)I associate it with'

    for dict in generated_file:

        if "emotional" in list(dict.keys())[0]:

            generated_text = list(dict.get(list(dict.keys())[0])[0].values())[0]
            print(generated_text)
            generated_association = re.sub(regex, '', generated_text)
            generated_emo.append(generated_association.split(".")[0])

        if "neutral" in list(dict.keys())[0]:

            generated_text = list(dict.get(list(dict.keys())[0])[0].values())[0]
            generated_association = re.sub(regex, '', generated_text)
            generated_neu.append(generated_association.split(".")[0])



    classifier_neu = pipeline("zero-shot-classification", model="facebook/bart-base", multi_label=True)  # model="bert-base-german-cased"

    with open("C:\\Users\\laris\\Desktop\\GitHub\\bachelor-thesis\\BERT model\\zero_shot_english_generatedtext_neu.json", "w") as fout:   # HIER CONFIG EINFÜGEN
        json.dump(classifier_neu(generated_neu, candidate_labels=participant_associations_neu), fout)



    classifier_emo = pipeline("zero-shot-classification", model="facebook/bart-base", multi_label=True)  # model="bert-base-german-cased"

    with open("C:\\Users\\laris\\Desktop\\GitHub\\bachelor-thesis\\BERT model\\zero_shot_english_generatedtext_emo.json", "w") as fout2:    # HIER CONFIG EINFÜGEN
        json.dump(classifier_emo(generated_emo, candidate_labels=participant_associations_emo), fout2)




""" 
def zero_shot_generatedText_de():
    
    This function takes the associations created by the study participants and 
    the associations generated by the pipeline in German and passes them together 
    through a zero-shot pipeline. Following this, two json files (emotional and neutral) 
    are created containing the result of the pipeline. The result answers the 
    question, which study participant associations were assigned to which 
    generated associations?

    Parameters:
    -----------
    -
    
    Returns:
    --------
        Returns two json-files with the assignments of the generated associations to the ones from study participants.
   

    try:
        data = open("asso_split_de.txt")   # HIER CONFIG EINFÜGEN
        data = json.load(data)

        participant_associations_emo = data[0]
        participant_associations_neu = data[1]

    except FileNotFoundError:
        clean_features(features, translate=False)

    try: 
        generated_neu = []
        generated_emo = []

        generated_file = open("generated_de.txt")    # HIER CONFIG EINFÜGEN
        generated_file = json.load(generated_file)

    except FileNotFoundError:
        generating_german_features()


    regex = r'^(.*?)und wenn ich daran denke, assoziiere ich es mit'

    for dict in generated_file:

        if "emotional" in list(dict.keys())[0]:

            generated_text = dict.get(list(dict.keys())[0])
            generated_text = generated_text.get("generated_text")
            generated_association = re.sub(regex, '', generated_text)
            generated_emo.append(generated_association.split(".")[0].strip())

        if "neutral" in list(dict.keys())[0]:

            generated_text = dict.get(list(dict.keys())[0])
            generated_text = generated_text.get("generated_text")
            generated_association = re.sub(regex, '', generated_text)
            generated_neu.append(generated_association.split(".")[0].strip())

    uni_chr_re = re.compile(r'\\u([a-fA-F0-9]{4})')

    generated_neu_clean = []
    generated_emo_clean = []

    for i in range(len(generated_emo)):
        generated_emo_clean.append(uni_chr_re.sub(lambda m: chr(int(m.group(1), 16)), generated_emo[i]))
        generated_neu_clean.append(uni_chr_re.sub(lambda m: chr(int(m.group(1), 16)), generated_neu[i]))



    classifier_neu = pipeline("zero-shot-classification", model="distilbert-base-german-cased", multi_label=True)  # model="bert-base-german-cased"
    #result = classifier_neu(generated_neu_clean, candidate_labels=assoziationen_neu)

    with open("zero_shot_generatedtext_neu_de.txt", "w") as fout:       # HIER CONFIG EINFÜGEN
        json.dump(classifier_neu(generated_neu_clean, candidate_labels=participant_associations_neu), fout)



    classifier_emo = pipeline("zero-shot-classification", model="distilbert-base-german-cased", multi_label=True)  # model="bert-base-german-cased"
    #result = classifier_emo(generated_emo_clean, candidate_labels=assoziationen_emo)

    with open("zero_shot_generatedtext_emo_de.txt", "w") as fout:         # HIER CONFIG EINFÜGEN
        json.dump(classifier_emo(generated_emo_clean, candidate_labels=participant_associations_emo), fout) """




#clean_features(features)
zero_shot_generatedText_en()