from transformers import pipeline
import json
import re
import pandas as pd
#from serious_generating import *
from configparser import ConfigParser

config = ConfigParser()
config.read('config.ini')


features = pd.read_csv(config['load_paths']['filepath_feat'], sep='\t', usecols=[1, 2, 3, 6], encoding="utf-8")   # HIER CONFIG EINFÜGEN


def clean_features(features):
    """
    This function extracts the features of the Pseudowörter and cleans them.
    After that it splits them into neutral and emotional features and returns a 
    json-file with a list of lists of these cleaned and split features.

    Parameters:
    -----------
    translate : boolean
        If translate is True, the features are translated into English.
        If it is False, they stay in German.
    
    Returns:
    --------
        Returns a json-file with a list of lists of the cleaned and split features.
    """

    associations_neu = []
    associations_emo = []
    filename = "C:\\Users\\laris\\Desktop\\GitHub\\bachelor-thesis\\BERT model\\translated_asso_split.json" # HIER CONFIG EINFÜGEN


    for i in range(len(features)):

        clean_association = re.sub(r'\s*\+\s*', ', ', features['features'][i])

        if features["emotionality"][i] == "neu":
            associations_neu.append(clean_association)

        if features["emotionality"][i] == "emo":
            associations_emo.append(clean_association)


    all_associations = [associations_emo, associations_neu]

    with open(filename, "w") as f2out:
        json.dump(all_associations, f2out)


def getDefinitions(definitionsFile):
    """
    This function takes the DefinitionsFile with the definitions 
    of the Pseudowörter and returns the definitions.

    Parameters:
    -----------
    definitionsFile : pd.DataFrame
       Contains the definitions of the Pseudowörter.
   
    
    Returns:
    --------
    defini : list
        Contains all definitions.
    """
    defini_neu = []
    defini_emo = []

    for m in range(len(definitionsFile)):

        defini_emo.append(definitionsFile["Konzept "][m])
        defini_neu.append(definitionsFile["N_Konzept"][m])
    
    return defini_neu, defini_emo


def zero_shot_generatedText_en():
    """
    This function takes the associations created by the study participants and 
    the associations generated by the pipeline in English and passes them together 
    through a zero-shot pipeline. Following this, two json files (emotional and neutral) 
    are created containing the result of the pipeline. The result answers the 
    question, which study participant associations were assigned to which 
    generated associations?

    Parameters:
    -----------
    -
    
    Returns:
    --------
        Returns two json-files with the assignments of the generated associations to the ones from study participants.
    """
    
    data = open("C:\\Users\\laris\\Desktop\\GitHub\\bachelor-thesis\\BERT model\\translated_asso_split.json")   # HIER CONFIG EINFÜGEN
    data = json.load(data)
    
    #definitionsFile = pd.read_csv(config['load_paths']['filepath_definition'], sep='\t', usecols=[1,2,3], encoding='utf-8')

    participant_associations_emo = data[0]
    participant_associations_neu = data[1]


    generated_file = open("C:\\Users\\laris\\Desktop\\GitHub\\bachelor-thesis\\BERT model\\unmasked_en.json")   # HIER CONFIG EINFÜGEN
    generated_file = json.load(generated_file)

    generated_neu = []
    generated_emo = []
    

    for dict in generated_file:

        if "emotional" in list(dict.keys())[0]:

            generated_text = list(dict.values())[0]
            print(generated_text)
            string = ""
            for asso in generated_text:
                string = string + asso.strip() + ", "

            generated_emo.append(string[:-2])

        if "neutral" in list(dict.keys())[0]:

            generated_text = list(dict.values())[0]
            string2 = ""
            for asso2 in generated_text:
                string2 = string2 + asso2.strip() + ", "
            generated_neu.append(string2[:-2])

    #defini_neu, defini_emo = getDefinitions(definitionsFile)
     
    classifier_neu = pipeline("zero-shot-classification", model="facebook/bart-base", multi_label=True)  # model="bert-base-german-cased"

    with open("C:\\Users\\laris\\Desktop\\GitHub\\bachelor-thesis\\BERT model\\zero_shot_english_masked_neu.json", "w") as fout:   # HIER CONFIG EINFÜGEN
        json.dump(classifier_neu(generated_neu, candidate_labels=participant_associations_neu), fout)
        #json.dump(classifier_neu(generated_neu, candidate_labels=defini_neu), fout)



    classifier_emo = pipeline("zero-shot-classification", model="facebook/bart-base", multi_label=True)  # model="bert-base-german-cased"

    with open("C:\\Users\\laris\\Desktop\\GitHub\\bachelor-thesis\\BERT model\\zero_shot_english_masked_emo.json", "w") as fout2:    # HIER CONFIG EINFÜGEN
        json.dump(classifier_emo(generated_emo, candidate_labels=participant_associations_emo), fout2)
        #json.dump(classifier_emo(generated_emo, candidate_labels=defini_emo), fout2)


zero_shot_generatedText_en()